"""
Script para recuperar coment√°rios perdidos dos canais problem√°ticos
Identifica canais sem coment√°rios mas que t√™m v√≠deos com engajamento
"""
import asyncio
import os
from datetime import datetime, timedelta
from dotenv import load_dotenv
import logging

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Carregar vari√°veis de ambiente
load_dotenv()

async def recuperar_comentarios_perdidos():
    """Recupera coment√°rios dos canais que n√£o foram salvos por falha do GPT"""

    # Importar ap√≥s carregar .env
    from database import SupabaseClient
    from collector import YouTubeCollector
    from gpt_analyzer import GPTAnalyzer
    from database_comments import CommentsDB

    print("\n" + "="*60)
    print("RECUPERA√á√ÉO DE COMENT√ÅRIOS PERDIDOS")
    print("="*60)

    try:
        # Inicializar componentes
        db = SupabaseClient()
        collector = YouTubeCollector()
        gpt_analyzer = GPTAnalyzer()
        comments_db = CommentsDB()

        # Buscar canais tipo="nosso" sem coment√°rios
        print("\n[1/5] Identificando canais problem√°ticos...")

        # Buscar todos os canais tipo="nosso"
        canais_nosso = db.supabase.table('canais_monitorados')\
            .select('*')\
            .eq('tipo', 'nosso')\
            .eq('status', 'ativo')\
            .execute()

        # Buscar canais que t√™m coment√°rios
        canais_com_comentarios_query = db.supabase.table('video_comments')\
            .select('canal_id')\
            .execute()

        canais_com_comentarios = set()
        for c in canais_com_comentarios_query.data or []:
            if c.get('canal_id'):
                canais_com_comentarios.add(c['canal_id'])

        # Identificar canais sem coment√°rios
        canais_problematicos = []
        for canal in canais_nosso.data or []:
            if canal['id'] not in canais_com_comentarios:
                # Verificar se tem videos_coletados > 0 (indica que deveria ter coment√°rios)
                if canal.get('videos_coletados', 0) > 0:
                    canais_problematicos.append(canal)

        print(f"[INFO] {len(canais_problematicos)} canais problem√°ticos identificados")

        if not canais_problematicos:
            print("[OK] Nenhum canal problem√°tico encontrado!")
            return

        # Mostrar lista dos canais
        print("\n[CANAIS A RECUPERAR]")
        for i, canal in enumerate(canais_problematicos[:12], 1):  # Limitar a 12 mais cr√≠ticos
            nome_safe = canal['nome_canal'].encode('ascii', 'ignore').decode('ascii')
            print(f"  {i:2}. {nome_safe:30} | Videos: {canal.get('videos_coletados', 0):3} | Subnicho: {canal.get('subnicho', 'N/A')}")

        # Confirmar
        print(f"\n[2/5] Iniciando coleta de coment√°rios...")
        print("-" * 50)

        total_comentarios_recuperados = 0
        total_comentarios_analisados = 0
        canais_processados = 0
        canais_com_sucesso = 0

        # Processar cada canal
        for idx, canal in enumerate(canais_problematicos[:12], 1):  # Limitar aos 12 mais importantes
            try:
                print(f"\n[CANAL {idx}/12] {canal['nome_canal']}")
                print(f"  URL: {canal['url_canal']}")

                # Obter channel_id
                channel_id = await collector.get_channel_id(canal['url_canal'], canal['nome_canal'])
                if not channel_id:
                    print(f"  [ERRO] N√£o foi poss√≠vel obter channel_id")
                    continue

                print(f"  [OK] Channel ID: {channel_id}")

                # Buscar v√≠deos recentes
                videos = await collector.get_channel_videos(channel_id, canal['nome_canal'], days=60)  # √öltimos 60 dias

                if not videos:
                    print(f"  [AVISO] Nenhum v√≠deo encontrado nos √∫ltimos 60 dias")
                    continue

                print(f"  [OK] {len(videos)} v√≠deos encontrados")

                # Processar os 5 v√≠deos mais populares
                videos_sorted = sorted(videos, key=lambda x: x.get('views_atuais', 0), reverse=True)
                videos_to_process = videos_sorted[:5]

                comentarios_canal = 0
                comentarios_analisados_canal = 0

                for video in videos_to_process:
                    video_id = video['video_id']
                    titulo_safe = video['titulo'][:50].encode('ascii', 'ignore').decode('ascii')
                    print(f"\n    [VIDEO] {titulo_safe}...")
                    print(f"           Views: {video['views_atuais']:,}")

                    # Coletar coment√°rios
                    comments = await collector.get_video_comments(
                        video_id,
                        video['titulo'],
                        max_results=100  # At√© 100 coment√°rios por v√≠deo
                    )

                    if not comments or len(comments) == 0:
                        print(f"           Sem coment√°rios")
                        continue

                    print(f"           {len(comments)} coment√°rios encontrados")

                    # Tentar analisar com GPT
                    analyzed_comments = None
                    try:
                        analyzed_comments = await gpt_analyzer.analyze_batch(
                            comments=comments,
                            video_title=video['titulo'],
                            canal_name=canal['nome_canal'],
                            batch_size=15
                        )

                        if analyzed_comments and len(analyzed_comments) > 0:
                            print(f"           ‚úÖ {len(analyzed_comments)} analisados com GPT")
                            comentarios_analisados_canal += len(analyzed_comments)
                    except Exception as gpt_error:
                        print(f"           ‚ö†Ô∏è GPT falhou: {str(gpt_error)[:50]}")
                        analyzed_comments = None

                    # Preparar coment√°rios para salvar (com ou sem an√°lise)
                    comments_to_save = []

                    if analyzed_comments:
                        comments_to_save = analyzed_comments
                    else:
                        # Salvar sem an√°lise (para n√£o perder dados)
                        for comment in comments:
                            comment_data = {
                                'comment_id': comment.get('comment_id'),
                                'video_id': video_id,
                                'canal_id': canal['id'],
                                'author': comment.get('author'),
                                'comment_text_original': comment.get('text', ''),
                                'published_at': comment.get('published_at'),
                                'like_count': comment.get('like_count', 0),
                                'reply_count': comment.get('reply_count', 0),
                                # Sem an√°lise GPT
                                'sentiment_category': None,
                                'sentiment_score': None,
                                'priority_score': None,
                                'emotional_tone': None,
                                'requires_response': False,
                                'suggested_response': None,
                                'analyzed_at': None
                            }
                            comments_to_save.append(comment_data)

                    # Salvar no banco
                    if comments_to_save:
                        try:
                            await comments_db.save_video_comments(
                                video_id=video_id,
                                canal_id=canal['id'],
                                comments=comments_to_save
                            )
                            print(f"           üíæ {len(comments_to_save)} salvos no banco")
                            comentarios_canal += len(comments_to_save)
                        except Exception as save_error:
                            print(f"           ‚ùå Erro ao salvar: {str(save_error)[:50]}")

                if comentarios_canal > 0:
                    print(f"\n  [RESUMO] {comentarios_canal} coment√°rios recuperados ({comentarios_analisados_canal} com an√°lise GPT)")
                    total_comentarios_recuperados += comentarios_canal
                    total_comentarios_analisados += comentarios_analisados_canal
                    canais_com_sucesso += 1

                canais_processados += 1

                # Pequena pausa entre canais
                if idx < len(canais_problematicos[:12]):
                    await asyncio.sleep(2)

            except Exception as e:
                print(f"\n  [ERRO] Erro ao processar canal {canal['nome_canal']}: {str(e)}")
                continue

        # Relat√≥rio final
        print("\n" + "="*60)
        print("RELAT√ìRIO DE RECUPERA√á√ÉO")
        print("="*60)
        print(f"[INFO] Canais processados: {canais_processados}")
        print(f"[OK] Canais com sucesso: {canais_com_sucesso}")
        print(f"[INFO] Total de coment√°rios recuperados: {total_comentarios_recuperados}")
        print(f"[INFO] Coment√°rios com an√°lise GPT: {total_comentarios_analisados}")
        print(f"[INFO] Coment√°rios sem an√°lise (para reprocessar): {total_comentarios_recuperados - total_comentarios_analisados}")

        # M√©tricas do GPT
        if total_comentarios_analisados > 0:
            metrics = gpt_analyzer.get_daily_metrics()
            print(f"\n[METRICS] Uso do GPT:")
            print(f"  Tokens entrada: {metrics['total_tokens_input']:,}")
            print(f"  Tokens sa√≠da: {metrics['total_tokens_output']:,}")
            print(f"  Custo estimado: ${metrics['estimated_cost_usd']:.4f}")

        print("\n[OK] RECUPERA√á√ÉO CONCLU√çDA!")
        print("="*60)

        # Salvar relat√≥rio
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"relatorio_recuperacao_{timestamp}.txt"

        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"RELAT√ìRIO DE RECUPERA√á√ÉO DE COMENT√ÅRIOS\n")
            f.write(f"Data: {datetime.now().strftime('%d/%m/%Y %H:%M')}\n")
            f.write(f"{'='*60}\n\n")
            f.write(f"Canais processados: {canais_processados}\n")
            f.write(f"Canais com sucesso: {canais_com_sucesso}\n")
            f.write(f"Total recuperado: {total_comentarios_recuperados}\n")
            f.write(f"Com an√°lise GPT: {total_comentarios_analisados}\n")
            f.write(f"Sem an√°lise: {total_comentarios_recuperados - total_comentarios_analisados}\n\n")

            f.write("CANAIS PROCESSADOS:\n")
            for canal in canais_problematicos[:canais_processados]:
                f.write(f"- {canal['nome_canal']}\n")

        print(f"\n[SAVE] Relat√≥rio salvo em: {filename}")

    except Exception as e:
        print(f"\n[ERRO] Erro na recupera√ß√£o: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(recuperar_comentarios_perdidos())