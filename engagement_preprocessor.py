#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Sistema de pr√©-processamento de dados de engajamento.
Executa ap√≥s a coleta di√°ria para processar e armazenar dados em cache.

Data: 29/01/2025
"""

import logging
import json
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Any, Optional
from database import SupabaseClient

logger = logging.getLogger(__name__)


class EngagementPreprocessor:
    """
    Pr√©-processa dados de engajamento e armazena em cache.
    Executa como √∫ltimo step da coleta di√°ria.
    """

    def __init__(self, db: SupabaseClient = None):
        """
        Inicializa o pr√©-processador.

        Args:
            db: Cliente do Supabase (opcional, cria novo se n√£o fornecido)
        """
        self.db = db or SupabaseClient()

    async def build_engagement_cache(self) -> Dict[str, Any]:
        """
        Constr√≥i cache completo de engajamento para todos os canais.
        Executa AP√ìS daily_analysis_job (√∫ltimo step).

        Returns:
            Dict com estat√≠sticas do processamento
        """
        try:
            logger.info("=" * 80)
            logger.info("üîÑ CONSTRUINDO CACHE DE ENGAJAMENTO")
            logger.info("=" * 80)

            start_time = datetime.now()

            # Buscar apenas canais "nossos" ativos
            canais_response = self.db.supabase.table('canais_monitorados')\
                .select('id, nome_canal')\
                .eq('tipo', 'nosso')\
                .eq('status', 'ativo')\
                .execute()

            if not canais_response.data:
                logger.warning("‚ö†Ô∏è Nenhum canal 'nosso' ativo encontrado")
                return {'processed': 0, 'failed': 0, 'total': 0}

            canais = canais_response.data
            total_canais = len(canais)

            logger.info(f"üìä {total_canais} canais para processar")

            processed = 0
            failed = 0

            for index, canal in enumerate(canais, 1):
                canal_id = canal['id']
                canal_nome = canal['nome_canal']

                try:
                    logger.info(f"[{index}/{total_canais}] Processando: {canal_nome} (ID: {canal_id})")

                    success = await self.process_and_cache_canal(canal_id)

                    if success:
                        processed += 1
                        logger.info(f"‚úÖ [{index}/{total_canais}] {canal_nome} - Cache atualizado")
                    else:
                        failed += 1
                        logger.warning(f"‚ö†Ô∏è [{index}/{total_canais}] {canal_nome} - Sem dados para cache")

                except Exception as e:
                    failed += 1
                    logger.error(f"‚ùå [{index}/{total_canais}] Erro ao processar {canal_nome}: {e}")
                    import traceback
                    logger.error(traceback.format_exc())

            # Limpar cache expirado
            try:
                cleanup_result = self.db.supabase.rpc('delete_expired_engagement_cache').execute()
                if cleanup_result.data is not None:
                    logger.info(f"üßπ Cache expirado limpo: {cleanup_result.data} registros")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro ao limpar cache expirado: {e}")

            elapsed_time = (datetime.now() - start_time).total_seconds()

            logger.info("=" * 80)
            logger.info("‚úÖ CACHE DE ENGAJAMENTO CONCLU√çDO")
            logger.info(f"‚úÖ Processados: {processed}/{total_canais}")
            logger.info(f"‚ùå Falhas: {failed}/{total_canais}")
            logger.info(f"‚è±Ô∏è Tempo total: {elapsed_time:.1f}s")
            logger.info("=" * 80)

            return {
                'processed': processed,
                'failed': failed,
                'total': total_canais,
                'elapsed_seconds': elapsed_time
            }

        except Exception as e:
            logger.error(f"‚ùå Erro cr√≠tico no build_engagement_cache: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {'processed': 0, 'failed': 0, 'total': 0}

    async def process_and_cache_canal(self, canal_id: int) -> bool:
        """
        Processa e armazena cache de engajamento para UM canal.

        Args:
            canal_id: ID do canal para processar

        Returns:
            True se sucesso, False se n√£o h√° dados ou erro
        """
        try:
            start_time = datetime.now()

            # Usar a fun√ß√£o existente para obter dados de engajamento
            engagement_data = await self.db.get_canal_engagement_data(canal_id)

            if not engagement_data:
                logger.info(f"   ‚ÑπÔ∏è Canal {canal_id}: sem dados de engajamento")
                return False

            # Calcular tempo de processamento
            processing_time_ms = int((datetime.now() - start_time).total_seconds() * 1000)

            # Contar totais - usar o summary que sempre existe
            total_comments = engagement_data.get('summary', {}).get('total_comments', 0)
            total_videos = len(engagement_data.get('videos_summary', []))

            # Preparar dados para cache
            cache_data = {
                'summary': engagement_data.get('summary', {}),
                'videos_summary': engagement_data.get('videos_summary', []),
                'actionable_comments': engagement_data.get('actionable_comments', []),
                'positive_comments': engagement_data.get('positive_comments', []),
                'negative_comments': engagement_data.get('negative_comments', []),
                'problem_comments': engagement_data.get('problem_comments', [])
            }

            # Calcular expira√ß√£o (6h a partir de agora)
            expires_at = datetime.now(timezone.utc) + timedelta(hours=6)

            # Salvar no cache (upsert para atualizar se j√° existe)
            cache_response = self.db.supabase.table('engagement_cache').upsert({
                'canal_id': canal_id,
                'data': cache_data,
                'processed_at': datetime.now(timezone.utc).isoformat(),
                'expires_at': expires_at.isoformat(),
                'total_comments': total_comments,
                'total_videos': total_videos,
                'processing_time_ms': processing_time_ms,
                'updated_at': datetime.now(timezone.utc).isoformat()
            }, on_conflict='canal_id').execute()

            if cache_response.data:
                logger.info(f"   üíæ Cache salvo: {total_comments} coment√°rios, "
                          f"{total_videos} v√≠deos, {processing_time_ms}ms")
                return True
            else:
                logger.error(f"   ‚ùå Falha ao salvar cache para canal {canal_id}")
                return False

        except Exception as e:
            logger.error(f"   ‚ùå Erro ao processar canal {canal_id}: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    async def get_cached_engagement(self, canal_id: int) -> Optional[Dict[str, Any]]:
        """
        Busca dados de engajamento do cache.

        Args:
            canal_id: ID do canal

        Returns:
            Dados do cache se dispon√≠vel e v√°lido, None caso contr√°rio
        """
        try:
            # Buscar cache v√°lido (n√£o expirado)
            cache_response = self.db.supabase.table('engagement_cache')\
                .select('*')\
                .eq('canal_id', canal_id)\
                .gt('expires_at', datetime.now(timezone.utc).isoformat())\
                .execute()

            if not cache_response.data:
                logger.info(f"‚ö†Ô∏è Cache miss para canal {canal_id} (vazio ou expirado)")
                return None

            cache_entry = cache_response.data[0]

            # Adicionar metadados do cache ao response
            result = cache_entry['data']
            result['_cache_metadata'] = {
                'cached': True,
                'processed_at': cache_entry['processed_at'],
                'expires_at': cache_entry['expires_at'],
                'total_comments': cache_entry.get('total_comments', 0),
                'total_videos': cache_entry.get('total_videos', 0),
                'processing_time_ms': cache_entry.get('processing_time_ms', 0)
            }

            logger.info(f"‚úÖ Cache hit para canal {canal_id} "
                       f"({cache_entry.get('total_comments', 0)} coment√°rios)")

            return result

        except Exception as e:
            logger.error(f"‚ùå Erro ao buscar cache para canal {canal_id}: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return None

    async def force_rebuild_cache(self, canal_id: Optional[int] = None) -> Dict[str, Any]:
        """
        For√ßa reconstru√ß√£o do cache (√∫til para testes ou corre√ß√µes).

        Args:
            canal_id: ID espec√≠fico do canal ou None para todos

        Returns:
            Estat√≠sticas do processamento
        """
        try:
            if canal_id:
                logger.info(f"üîÑ For√ßando rebuild do cache para canal {canal_id}")
                success = await self.process_and_cache_canal(canal_id)
                return {
                    'processed': 1 if success else 0,
                    'failed': 0 if success else 1,
                    'total': 1
                }
            else:
                logger.info("üîÑ For√ßando rebuild do cache para TODOS os canais")
                return await self.build_engagement_cache()

        except Exception as e:
            logger.error(f"‚ùå Erro ao for√ßar rebuild: {e}")
            return {'processed': 0, 'failed': 1, 'total': 1}

    async def get_cache_stats(self) -> Dict[str, Any]:
        """
        Retorna estat√≠sticas do cache.

        Returns:
            Dict com estat√≠sticas do cache
        """
        try:
            # Total de registros em cache
            total_response = self.db.supabase.table('engagement_cache')\
                .select('id', count='exact')\
                .execute()

            # Registros v√°lidos (n√£o expirados)
            valid_response = self.db.supabase.table('engagement_cache')\
                .select('id', count='exact')\
                .gt('expires_at', datetime.now(timezone.utc).isoformat())\
                .execute()

            # Registros expirados
            expired_response = self.db.supabase.table('engagement_cache')\
                .select('id', count='exact')\
                .lte('expires_at', datetime.now(timezone.utc).isoformat())\
                .execute()

            return {
                'total_cached': total_response.count or 0,
                'valid_cached': valid_response.count or 0,
                'expired_cached': expired_response.count or 0,
                'cache_hit_rate': 0  # Pode ser calculado com m√©tricas adicionais
            }

        except Exception as e:
            logger.error(f"‚ùå Erro ao obter estat√≠sticas do cache: {e}")
            return {
                'total_cached': 0,
                'valid_cached': 0,
                'expired_cached': 0,
                'cache_hit_rate': 0
            }


# Fun√ß√£o helper para usar no main.py
async def build_engagement_cache():
    """
    Fun√ß√£o helper para construir cache de engajamento.
    Chamada ap√≥s daily_analysis_job.
    """
    preprocessor = EngagementPreprocessor()
    return await preprocessor.build_engagement_cache()