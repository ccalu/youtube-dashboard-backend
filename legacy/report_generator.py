"""
report_generator.py - Gerador de Relat√≥rios Semanais
Author: Claude Code
Date: 2024-11-05

Gera relat√≥rio semanal completo com:
- Top 10 v√≠deos (nossos + minerados)
- Performance por subniche
- Insights autom√°ticos
- Gap analysis
- A√ß√µes recomendadas
"""

from datetime import datetime, timedelta
from typing import Dict, List
import json
from analyzer import Analyzer


class ReportGenerator:
    """Gerador de relat√≥rios semanais"""

    def __init__(self, db_client):
        """
        Inicializa o gerador

        Args:
            db_client: Cliente Supabase para acesso ao banco
        """
        self.db = db_client
        self.analyzer = Analyzer(db_client)

    # =========================================================================
    # GERA√á√ÉO DO RELAT√ìRIO COMPLETO
    # =========================================================================

    def generate_weekly_report(self) -> Dict:
        """
        Gera relat√≥rio semanal completo

        Returns:
            Dict com todos os dados do relat√≥rio
        """
        print("[ReportGenerator] Gerando relat√≥rio semanal...")

        # Calcular per√≠odo (√∫ltima semana)
        today = datetime.now()
        week_end = today.strftime("%Y-%m-%d")
        week_start = (today - timedelta(days=7)).strftime("%Y-%m-%d")

        # Gerar todas as se√ß√µes
        report = {
            'week_start': week_start,
            'week_end': week_end,
            'generated_at': datetime.now().isoformat(),
            'top_10_nossos': self._get_top_10_videos('nosso', week_start, week_end),
            'top_10_minerados': self._get_top_10_videos('minerado', week_start, week_end),
            'top_10_keywords': self._get_top_10_keywords_by_subniche(),
            'performance_by_subniche': self._get_performance_by_subniche(week_start),
            'recommended_actions': self._generate_recommendations()
        }

        # Salvar no banco
        self._save_report(report)

        print("[ReportGenerator] Relat√≥rio gerado com sucesso!")
        return report

    # =========================================================================
    # TOP 10 V√çDEOS
    # =========================================================================

    def _get_top_10_videos(self, tipo_canal: str, week_start: str, week_end: str) -> List[Dict]:
        """
        Busca top 10 v√≠deos √öNICOS por tipo de canal (nossos ou minerados)

        IMPORTANTE: Agrupa por video_id para evitar duplicatas (mesmo v√≠deo em m√∫ltiplos dias)

        Args:
            tipo_canal: 'nosso' ou 'minerado'
            week_start: Data in√≠cio da semana
            week_end: Data fim da semana

        Returns:
            Lista com top 10 v√≠deos √öNICOS ordenados por views (sem repeti√ß√µes)
        """
        print(f"[ReportGenerator] Buscando top 10 v√≠deos √öNICOS ({tipo_canal})...")

        # Buscar v√≠deos postados nos √∫ltimos 30 dias com 10k+ views
        cutoff_date_30d = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")

        # Query: buscar TODOS os v√≠deos (n√£o limitar ainda)
        response = self.db.table("videos_historico")\
            .select("*, canais_monitorados!inner(nome_canal, tipo, id, subnicho)")\
            .eq("canais_monitorados.tipo", tipo_canal)\
            .gte("data_publicacao", cutoff_date_30d)\
            .gte("views_atuais", 10000)\
            .gte("data_coleta", week_start)\
            .lte("data_coleta", week_end)\
            .order("views_atuais", desc=True)\
            .execute()

        all_videos = response.data

        # AGRUPAR por video_id pegando registro mais recente (evita duplicatas)
        videos_dict = {}
        for video in all_videos:
            video_id = video['video_id']

            if video_id not in videos_dict:
                videos_dict[video_id] = video
            else:
                # Se j√° existe, pega o mais recente (data_coleta mais recente)
                if video['data_coleta'] > videos_dict[video_id]['data_coleta']:
                    videos_dict[video_id] = video

        # Converter dict para lista e ordenar por views
        unique_videos = list(videos_dict.values())
        unique_videos.sort(key=lambda x: x['views_atuais'], reverse=True)

        # Pegar top 10
        top_10 = unique_videos[:10]

        # Calcular inscritos ganhos para cada canal nos √∫ltimos 7 dias
        result = []
        for video in top_10:
            canal_id = video['canais_monitorados']['id']

            # Buscar dados do canal nos √∫ltimos 7 dias
            subs_gained = self._get_subscribers_gained(canal_id, 7)

            result.append({
                'video_id': video['video_id'],
                'titulo': video['titulo'],
                'canal_nome': video['canais_monitorados']['nome_canal'],
                'canal_id': canal_id,
                'canal_subnicho': video['canais_monitorados']['subnicho'],
                'views_atuais': video['views_atuais'],
                'likes': video.get('likes', 0),
                'duracao': video.get('duracao', 0),
                'views_7d': video['views_atuais'],
                'subscribers_gained_7d': subs_gained,
                'url_video': video.get('url_video', f"https://youtube.com/watch?v={video['video_id']}")
            })

        print(f"[ReportGenerator] {len(result)} v√≠deos √öNICOS encontrados ({tipo_canal})")
        return result

    def _get_subscribers_gained(self, canal_id: int, days: int) -> int:
        """Calcula inscritos ganhos no per√≠odo"""
        try:
            # Buscar snapshot atual
            current = self.db.table("dados_canais_historico")\
                .select("inscritos")\
                .eq("canal_id", canal_id)\
                .order("data_coleta", desc=True)\
                .limit(1)\
                .execute()

            # Buscar snapshot N dias atr√°s
            past_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
            past = self.db.table("dados_canais_historico")\
                .select("inscritos")\
                .eq("canal_id", canal_id)\
                .lte("data_coleta", past_date)\
                .order("data_coleta", desc=True)\
                .limit(1)\
                .execute()

            if current.data and past.data:
                return current.data[0]['inscritos'] - past.data[0]['inscritos']

        except Exception as e:
            print(f"[ReportGenerator] Erro ao calcular inscritos: {e}")

        return 0

    # =========================================================================
    # PERFORMANCE POR SUBNICHE
    # =========================================================================

    def _get_performance_by_subniche(self, week_start: str) -> List[Dict]:
        """
        Calcula performance por subniche (√∫ltima semana vs semana anterior)

        Args:
            week_start: Data in√≠cio da semana atual

        Returns:
            Lista com performance de cada subniche
        """
        print("[ReportGenerator] Calculando performance por subniche...")

        # Buscar todos os subniches ativos
        subniches_response = self.db.table("canais_monitorados")\
            .select("subnicho")\
            .eq("tipo", "nosso")\
            .eq("status", "ativo")\
            .execute()

        subniches = list(set([c['subnicho'] for c in subniches_response.data]))

        result = []
        for subniche in subniches:
            # Views √∫ltima semana
            week_start_date = datetime.strptime(week_start, "%Y-%m-%d")
            week_end_date = week_start_date + timedelta(days=7)

            views_current = self._get_total_views_for_subniche(
                subniche,
                week_start_date.strftime("%Y-%m-%d"),
                week_end_date.strftime("%Y-%m-%d")
            )

            # Views semana anterior
            prev_week_start = (week_start_date - timedelta(days=7)).strftime("%Y-%m-%d")
            prev_week_end = week_start_date.strftime("%Y-%m-%d")

            views_previous = self._get_total_views_for_subniche(
                subniche,
                prev_week_start,
                prev_week_end
            )

            # Calcular crescimento %
            if views_previous > 0:
                growth_pct = ((views_current - views_previous) / views_previous) * 100
            else:
                growth_pct = 100.0 if views_current > 0 else 0.0

            # Gerar insight autom√°tico
            insight = self._generate_insight_for_subniche(subniche, growth_pct, views_current)

            # Totais por per√≠odo de publica√ß√£o
            total_7d = self._get_total_views_by_publication(subniche, days=7)
            total_30d = self._get_total_views_by_publication(subniche, days=30)

            result.append({
                'subniche': subniche,
                'views_current_week': views_current,
                'views_previous_week': views_previous,
                'growth_percentage': round(growth_pct, 1),
                'insight': insight,
                'total_views_7d': total_7d['total_views'],
                'video_count_7d': total_7d['video_count'],
                'total_views_30d': total_30d['total_views'],
                'video_count_30d': total_30d['video_count']
            })

        print(f"[ReportGenerator] {len(result)} subniches analisados")
        return result

    def _get_total_views_for_subniche(self, subniche: str, date_start: str, date_end: str) -> int:
        """
        Calcula total de views √öNICO por v√≠deo para um subniche no per√≠odo

        IMPORTANTE: Remove duplicatas - cada v√≠deo conta apenas 1 vez (snapshot mais recente)
        """
        # V√≠deos publicados nos √∫ltimos 30 dias
        cutoff_30d = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")

        response = self.db.table("videos_historico")\
            .select("video_id, views_atuais, data_coleta, canais_monitorados!inner(subnicho, tipo)")\
            .eq("canais_monitorados.subnicho", subniche)\
            .eq("canais_monitorados.tipo", "nosso")\
            .gte("data_publicacao", cutoff_30d)\
            .gte("data_coleta", date_start)\
            .lte("data_coleta", date_end)\
            .order("data_coleta", desc=True)\
            .execute()

        # Remove duplicatas: mant√©m apenas snapshot mais recente de cada v√≠deo
        videos_dict = {}
        for video in response.data:
            video_id = video['video_id']
            if video_id not in videos_dict:
                videos_dict[video_id] = video['views_atuais']

        total_views = sum(videos_dict.values())
        print(f"[ReportGenerator] {subniche}: {len(videos_dict)} v√≠deos √∫nicos, {total_views:,} views totais no per√≠odo")
        return total_views

    def _get_total_views_by_publication(self, subniche: str, days: int) -> Dict:
        """
        Calcula total de views de v√≠deos PUBLICADOS nos √∫ltimos X dias

        Args:
            subniche: Nome do subniche
            days: Janela de publica√ß√£o (7 ou 30 dias)

        Returns:
            Dict com total_views e video_count
        """
        cutoff_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")

        # Buscar v√≠deos publicados nos √∫ltimos X dias
        response = self.db.table("videos_historico")\
            .select("video_id, views_atuais, data_coleta, canais_monitorados!inner(subnicho, tipo)")\
            .eq("canais_monitorados.subnicho", subniche)\
            .eq("canais_monitorados.tipo", "nosso")\
            .gte("data_publicacao", cutoff_date)\
            .order("data_coleta", desc=True)\
            .execute()

        # Remove duplicatas: mant√©m apenas snapshot mais recente de cada v√≠deo
        videos_dict = {}
        for video in response.data:
            video_id = video['video_id']
            if video_id not in videos_dict:
                videos_dict[video_id] = video['views_atuais']

        total_views = sum(videos_dict.values())
        video_count = len(videos_dict)

        print(f"[ReportGenerator] {subniche} ({days}d): {video_count} v√≠deos publicados, {total_views:,} views totais")
        return {
            'total_views': total_views,
            'video_count': video_count
        }

    def _generate_insight_for_subniche(self, subniche: str, growth_pct: float, views: int) -> str:
        """Gera insight autom√°tico baseado na performance"""
        if growth_pct > 10:
            return f"Excelente crescimento! {subniche} est√° performando acima da m√©dia. Continue investindo nesse tipo de conte√∫do."
        elif growth_pct > 5:
            return f"Crescimento s√≥lido. {subniche} est√° em boa trajet√≥ria. Mantenha a consist√™ncia de uploads."
        elif growth_pct > -5:
            return f"Est√°vel. {subniche} mant√©m performance consistente. Considere testar novos formatos de t√≠tulo."
        else:
            return f"Aten√ß√£o! {subniche} em queda. Revisar estrat√©gia de conte√∫do, thumbnails e t√≠tulos dos √∫ltimos v√≠deos."

    # =========================================================================
    # GAP ANALYSIS
    # =========================================================================

    def _get_gap_analysis(self) -> Dict:
        """
        Analisa gaps estrat√©gicos em tempo real para cada subniche

        Returns:
            Dict com gaps por subniche
        """
        print("[ReportGenerator] Analisando gaps estrat√©gicos...")

        # Buscar todos os subniches ativos
        subniches_response = self.db.table("canais_monitorados")\
            .select("subnicho")\
            .eq("tipo", "nosso")\
            .eq("status", "ativo")\
            .execute()

        subniches = list(set([c['subnicho'] for c in subniches_response.data]))

        # Analisar gaps para cada subniche
        gaps_by_subniche = {}
        total_gaps = 0

        for subniche in subniches:
            gaps_list = self.analyzer.analyze_gaps(subniche)

            if gaps_list:
                # Retornar formato NOVO (n√£o converter!)
                gaps_by_subniche[subniche] = gaps_list
                total_gaps += len(gaps_list)

        print(f"[ReportGenerator] {total_gaps} gaps encontrados em {len(gaps_by_subniche)} subniches")
        return gaps_by_subniche

    def _get_top_10_keywords_by_subniche(self) -> Dict[str, List[Dict]]:
        """
        Gera top 10 keywords para cada subniche ativo (√∫ltimos 30 dias)

        Returns:
            Dict com keywords por subniche: {subniche: [keywords]}
        """
        print("[ReportGenerator] Gerando top 10 keywords por subniche...")

        # Buscar subniches ativos
        subniches_response = self.db.table("canais_monitorados")\
            .select("subnicho")\
            .eq("tipo", "nosso")\
            .eq("status", "ativo")\
            .execute()

        subniches = list(set([c['subnicho'] for c in subniches_response.data]))

        # Gerar keywords para cada subniche
        keywords_by_subniche = {}
        total_keywords = 0

        for subniche in subniches:
            # Usa analyzer.analyze_keywords() que J√Å filtra por subniche
            keywords = self.analyzer.analyze_keywords(subniche=subniche, period_days=30)

            if keywords:
                keywords_by_subniche[subniche] = keywords[:10]  # Top 10
                total_keywords += len(keywords[:10])

        print(f"[ReportGenerator] {total_keywords} keywords geradas para {len(keywords_by_subniche)} subniches")
        return keywords_by_subniche

    # =========================================================================
    # AN√ÅLISES AVAN√áADAS (AL√âM DE T√çTULOS)
    # =========================================================================

    def _analyze_upload_frequency(self) -> Dict:
        """
        Analisa frequ√™ncia de upload nossos canais vs concorrentes (√∫ltimos 30 dias)

        Returns:
            Dict com an√°lise de frequ√™ncia por subniche
        """
        print("[ReportGenerator] Analisando frequ√™ncia de upload...")

        cutoff_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")

        # Buscar subniches
        response_subniches = self.db.table("canais_monitorados")\
            .select("subnicho")\
            .execute()

        subniches = list(set([item['subnicho'] for item in response_subniches.data]))

        frequency_analysis = {}

        for subniche in subniches:
            # Nossos canais
            response_nossos = self.db.table("videos_historico")\
                .select("canal_id, canais_monitorados!inner(nome_canal, tipo, subnicho)")\
                .eq("canais_monitorados.tipo", "nosso")\
                .eq("canais_monitorados.subnicho", subniche)\
                .gte("data_publicacao", cutoff_date)\
                .execute()

            nossos_videos = response_nossos.data
            nossos_canais = set([v['canal_id'] for v in nossos_videos])
            nossos_frequency = len(nossos_videos) / len(nossos_canais) if nossos_canais else 0

            # Concorrentes
            response_concorrentes = self.db.table("videos_historico")\
                .select("canal_id, canais_monitorados!inner(nome_canal, tipo, subnicho)")\
                .eq("canais_monitorados.tipo", "minerado")\
                .eq("canais_monitorados.subnicho", subniche)\
                .gte("data_publicacao", cutoff_date)\
                .execute()

            concorrentes_videos = response_concorrentes.data
            concorrentes_canais = set([v['canal_id'] for v in concorrentes_videos])
            concorrentes_frequency = len(concorrentes_videos) / len(concorrentes_canais) if concorrentes_canais else 0

            if nossos_frequency > 0 and concorrentes_frequency > 0:
                frequency_analysis[subniche] = {
                    'nossos_videos_per_canal': round(nossos_frequency, 1),
                    'concorrentes_videos_per_canal': round(concorrentes_frequency, 1),
                    'difference': round(concorrentes_frequency - nossos_frequency, 1)
                }

        print(f"[ReportGenerator] An√°lise de frequ√™ncia conclu√≠da para {len(frequency_analysis)} subniches")
        return frequency_analysis

    def _analyze_engagement(self) -> Dict:
        """
        Analisa taxa de engajamento (likes/views) nossos vs concorrentes

        Returns:
            Dict com an√°lise de engagement por subniche
        """
        print("[ReportGenerator] Analisando engagement...")

        cutoff_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")

        # Buscar subniches
        response_subniches = self.db.table("canais_monitorados")\
            .select("subnicho")\
            .execute()

        subniches = list(set([item['subnicho'] for item in response_subniches.data]))

        engagement_analysis = {}

        for subniche in subniches:
            # Nossos canais
            response_nossos = self.db.table("videos_historico")\
                .select("views_atuais, likes, canais_monitorados!inner(tipo, subnicho)")\
                .eq("canais_monitorados.tipo", "nosso")\
                .eq("canais_monitorados.subnicho", subniche)\
                .gte("data_publicacao", cutoff_date)\
                .gte("views_atuais", 1000)\
                .execute()

            nossos_videos = response_nossos.data

            # Concorrentes
            response_concorrentes = self.db.table("videos_historico")\
                .select("views_atuais, likes, canais_monitorados!inner(tipo, subnicho)")\
                .eq("canais_monitorados.tipo", "minerado")\
                .eq("canais_monitorados.subnicho", subniche)\
                .gte("data_publicacao", cutoff_date)\
                .gte("views_atuais", 1000)\
                .execute()

            concorrentes_videos = response_concorrentes.data

            if nossos_videos and concorrentes_videos:
                # Calcular taxa de engagement
                nossos_engagement = sum([
                    (v.get('likes', 0) / v['views_atuais'] * 100)
                    for v in nossos_videos if v['views_atuais'] > 0
                ]) / len(nossos_videos)

                concorrentes_engagement = sum([
                    (v.get('likes', 0) / v['views_atuais'] * 100)
                    for v in concorrentes_videos if v['views_atuais'] > 0
                ]) / len(concorrentes_videos)

                engagement_analysis[subniche] = {
                    'nossos_engagement_rate': round(nossos_engagement, 2),
                    'concorrentes_engagement_rate': round(concorrentes_engagement, 2),
                    'difference': round(concorrentes_engagement - nossos_engagement, 2)
                }

        print(f"[ReportGenerator] An√°lise de engagement conclu√≠da para {len(engagement_analysis)} subniches")
        return engagement_analysis

    def _analyze_video_duration(self) -> Dict:
        """
        Analisa dura√ß√£o m√©dia dos v√≠deos de sucesso (50k+ views)

        Returns:
            Dict com dura√ß√£o m√©dia por subniche
        """
        print("[ReportGenerator] Analisando dura√ß√£o de v√≠deos...")

        cutoff_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")

        # Buscar subniches
        response_subniches = self.db.table("canais_monitorados")\
            .select("subnicho")\
            .execute()

        subniches = list(set([item['subnicho'] for item in response_subniches.data]))

        duration_analysis = {}

        for subniche in subniches:
            # V√≠deos de sucesso (50k+ views)
            response = self.db.table("videos_historico")\
                .select("duracao, views_atuais, canais_monitorados!inner(subnicho, tipo)")\
                .eq("canais_monitorados.subnicho", subniche)\
                .gte("data_publicacao", cutoff_date)\
                .gte("views_atuais", 50000)\
                .execute()

            videos = response.data

            if videos:
                # Calcular dura√ß√£o m√©dia
                durations = [v.get('duracao', 0) for v in videos if v.get('duracao', 0) > 0]

                if durations:
                    avg_duration = sum(durations) / len(durations)

                    duration_analysis[subniche] = {
                        'avg_duration_seconds': round(avg_duration, 0),
                        'avg_duration_minutes': round(avg_duration / 60, 1),
                        'video_count': len(durations)
                    }

        print(f"[ReportGenerator] An√°lise de dura√ß√£o conclu√≠da para {len(duration_analysis)} subniches")
        return duration_analysis

    # =========================================================================
    # A√á√ïES RECOMENDADAS
    # =========================================================================

    def _generate_recommendations(self) -> Dict[str, Dict]:
        """
        Gera a√ß√µes recomendadas AGRUPADAS POR SUBNICHE

        üÜï NOVA ESTRUTURA: 1 card por subniche com todas as recomenda√ß√µes

        Garante que TODOS os subniches nossos aparecem (mesmo que seja s√≥ "continuar assim")

        Returns:
            Dict com subniches como keys e recomenda√ß√µes agrupadas como values
            {
                'Contos Familiares': {
                    'status': 'growing',
                    'growth_percentage': 15.0,
                    'recommendations': [...]
                },
                ...
            }
        """
        print("[ReportGenerator] Gerando recomenda√ß√µes agrupadas por subniche...")

        # Estrutura: dict de subniches com suas recomenda√ß√µes
        recommendations_by_subniche = {}

        # Buscar dados de performance
        performance_data = self._get_performance_by_subniche(
            (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d")
        )

        # Inicializar dict com TODOS os subniches "nosso" e determinar status
        for perf in performance_data:
            subniche = perf['subniche']
            growth = perf['growth_percentage']

            # Determinar status
            if growth > 10:
                status = 'growing'
            elif growth < -10:
                status = 'declining'
            else:
                status = 'stable'

            recommendations_by_subniche[subniche] = {
                'status': status,
                'growth_percentage': growth,
                'recommendations': []
            }

        # Helper function para adicionar recomenda√ß√£o a um subniche
        def add_recommendation(subniche, recommendation):
            if subniche in recommendations_by_subniche:
                recommendations_by_subniche[subniche]['recommendations'].append(recommendation)

        # =====================================================================
        # 1. NOSSOS CANAIS - PROBLEMAS URGENTES (Subnichos em queda acentuada)
        # =====================================================================
        for perf in performance_data:
            if perf['growth_percentage'] < -10:  # Queda >10%
                add_recommendation(perf['subniche'], {
                    'priority': 'urgent',
                    'category': 'NOSSOS CANAIS - PROBLEMA',
                    'title': f"üî¥ Queda acentuada de performance",
                    'description': f"Queda de {abs(perf['growth_percentage']):.1f}% nas views. Necess√°rio a√ß√£o imediata para reverter tend√™ncia negativa.",
                    'action': f"1) Revisar √∫ltimos 5 v√≠deos: thumbnails, t√≠tulos, hooks iniciais\n2) Comparar com concorrentes top deste subniche\n3) Testar novo formato de v√≠deo ou padr√£o de t√≠tulo\n4) Analisar reten√ß√£o de audi√™ncia (primeiros 30s)",
                    'impact': 'CR√çTICO',
                    'effort': 'Alto'
                })

        # =====================================================================
        # 2. NOSSOS CANAIS - O QUE FAZEMOS BEM E DEVEMOS CONTINUAR
        # =====================================================================
        # Identifica top performers (subniches com crescimento >15%)
        top_performers = sorted(performance_data, key=lambda x: x['growth_percentage'], reverse=True)[:3]

        for perf in top_performers:
            if perf['growth_percentage'] > 15:
                # Busca v√≠deos TOP REAIS desse subniche (√∫ltimos 30 dias)
                cutoff_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")

                top_videos_response = self.db.table("videos_historico")\
                    .select("titulo, views_atuais, canais_monitorados!inner(tipo, subnicho)")\
                    .eq("canais_monitorados.tipo", "nosso")\
                    .eq("canais_monitorados.subnicho", perf['subniche'])\
                    .gte("data_publicacao", cutoff_date)\
                    .gte("views_atuais", 50000)\
                    .order("views_atuais", desc=True)\
                    .limit(3)\
                    .execute()

                if top_videos_response.data and len(top_videos_response.data) > 0:
                    top_video = top_videos_response.data[0]
                    avg_views = sum(v['views_atuais'] for v in top_videos_response.data) / len(top_videos_response.data)

                    add_recommendation(perf['subniche'], {
                        'priority': 'medium',
                        'category': 'NOSSOS CANAIS - CONTINUAR',
                        'title': f"‚úÖ Performance excelente (+{perf['growth_percentage']:.1f}%)",
                        'description': f"Crescimento de {perf['growth_percentage']:.1f}% nas views. {len(top_videos_response.data)} v√≠deos com 50k+ views nos √∫ltimos 30 dias!",
                        'action': f"MANTER estrat√©gia atual:\n‚Ä¢ Continuar modelo que funciona (avg {avg_views:,.0f} views)\n‚Ä¢ Top v√≠deo: \"{top_video['titulo']}\" ({top_video['views_atuais']:,} views)\n‚Ä¢ Analisar esses {len(top_videos_response.data)} v√≠deos: o que t√™m em comum?\n‚Ä¢ Replicar formato em outros subniches se poss√≠vel",
                        'impact': 'M√âDIO',
                        'effort': 'Baixo',
                        'avg_views': int(avg_views)
                    })

        # =====================================================================
        # 3. NOSSOS CANAIS - O QUE FAZEMOS MAL E DEVEMOS MELHORAR
        # =====================================================================
        # Identifica underperformers (abaixo da m√©dia, mas n√£o em queda cr√≠tica)
        if performance_data:
            avg_growth = sum(p['growth_percentage'] for p in performance_data) / len(performance_data)
            underperformers = [p for p in performance_data if p['growth_percentage'] < avg_growth * 0.5 and p['growth_percentage'] >= -10][:3]

            for perf in underperformers:
                add_recommendation(perf['subniche'], {
                    'priority': 'medium',
                    'category': 'NOSSOS CANAIS - MELHORAR',
                    'title': f"‚ö†Ô∏è Performance abaixo da m√©dia",
                    'description': f"Crescimento de apenas {perf['growth_percentage']:.1f}% vs m√©dia geral de {avg_growth:.1f}%. H√° espa√ßo para otimiza√ß√£o.",
                    'action': f"1) Analisar top 3 v√≠deos dos concorrentes deste subniche\n2) Testar novos formatos de thumbnail (A/B test)\n3) Revisar SEO: t√≠tulo, descri√ß√£o, tags\n4) Avaliar hor√°rio de postagem e frequ√™ncia",
                    'impact': 'M√âDIO',
                    'effort': 'M√©dio'
                })

        # =====================================================================
        # 4. FREQU√äNCIA DE UPLOAD - An√°lise Comparativa
        # =====================================================================
        frequency_data = self._analyze_upload_frequency()

        for subniche, data in frequency_data.items():
            if data['difference'] > 3:  # Concorrentes postam 3+ v√≠deos a mais por canal
                add_recommendation(subniche, {
                    'priority': 'high',
                    'category': 'FREQU√äNCIA - AJUSTAR',
                    'title': f"üìÖ Frequ√™ncia de upload baixa",
                    'description': f"Concorrentes postam {data['concorrentes_videos_per_canal']:.1f} v√≠deos/canal vs nossos {data['nossos_videos_per_canal']:.1f} (√∫ltimos 30 dias). Diferen√ßa de {data['difference']:.1f} v√≠deos/canal.",
                    'action': f"1) Aumentar produ√ß√£o para igualar concorrentes\n2) Se n√£o conseguir produzir mais, priorizar qualidade sobre quantidade\n3) Considerar contratar editor adicional ou otimizar fluxo de produ√ß√£o\n4) Avaliar se falta de consist√™ncia afeta algoritmo do YouTube",
                    'impact': 'ALTO',
                    'effort': 'Alto'
                })
            elif data['difference'] < -3:  # Estamos postando muito mais
                add_recommendation(subniche, {
                    'priority': 'medium',
                    'category': 'FREQU√äNCIA - OTIMIZAR',
                    'title': f"üìπ Excesso de uploads",
                    'description': f"Estamos postando {data['nossos_videos_per_canal']:.1f} v√≠deos/canal vs {data['concorrentes_videos_per_canal']:.1f} dos concorrentes (√∫ltimos 30 dias).",
                    'action': f"Avaliar se o excesso de uploads est√° afetando qualidade ou engagement. Considerar reduzir frequ√™ncia e focar em v√≠deos com maior potencial de views.",
                    'impact': 'M√âDIO',
                    'effort': 'Baixo'
                })

        # =====================================================================
        # 5. ENGAGEMENT (LIKES/VIEWS) - An√°lise Comparativa
        # =====================================================================
        engagement_data = self._analyze_engagement()

        for subniche, data in engagement_data.items():
            if data['difference'] > 0.5:  # Concorrentes t√™m 0.5%+ engagement a mais
                add_recommendation(subniche, {
                    'priority': 'high',
                    'category': 'ENGAGEMENT - MELHORAR',
                    'title': f"üëç Baixo engagement",
                    'description': f"Taxa de likes nossos: {data['nossos_engagement_rate']:.2f}% vs concorrentes: {data['concorrentes_engagement_rate']:.2f}%. Diferen√ßa de {data['difference']:.2f}%.",
                    'action': f"1) Adicionar CTAs (Call To Action) mais fortes nos v√≠deos\n2) Pedir likes/comments de forma natural no in√≠cio E fim do v√≠deo\n3) Criar momentos mais \"meme-√°veis\" ou emocionais que incentivem rea√ß√£o\n4) Responder mais coment√°rios para estimular comunidade\n5) Analisar thumbnails - podem n√£o estar gerando expectativa suficiente",
                    'impact': 'ALTO',
                    'effort': 'M√©dio'
                })

        # =====================================================================
        # 6. DURA√á√ÉO DE V√çDEOS - An√°lise de Sucesso
        # =====================================================================
        duration_data = self._analyze_video_duration()

        for subniche, data in duration_data.items():
            if data['avg_duration_minutes'] > 0:
                add_recommendation(subniche, {
                    'priority': 'medium',
                    'category': 'DURA√á√ÉO - INSIGHT',
                    'title': f"‚è±Ô∏è Dura√ß√£o ideal identificada",
                    'description': f"V√≠deos de sucesso (50k+ views) t√™m m√©dia de {data['avg_duration_minutes']:.1f} minutos ({data['video_count']} v√≠deos analisados).",
                    'action': f"Usar {data['avg_duration_minutes']:.1f} minutos como refer√™ncia para novos v√≠deos. V√≠deos muito mais curtos ou longos podem performar pior.",
                    'impact': 'M√âDIO',
                    'effort': 'Baixo'
                })

        # =====================================================================
        # 7. GARANTIR QUE TODOS OS SUBNICHES T√äM PELO MENOS 1 RECOMENDA√á√ÉO
        # =====================================================================
        for subniche, data in recommendations_by_subniche.items():
            if len(data['recommendations']) == 0:
                # Adicionar recomenda√ß√£o padr√£o baseada no status
                if data['status'] == 'stable':
                    add_recommendation(subniche, {
                        'priority': 'low',
                        'category': 'NOSSOS CANAIS - MANTER',
                        'title': f"‚úÖ Performance est√°vel",
                        'description': f"Crescimento de {data['growth_percentage']:.1f}% nas views. Performance dentro do esperado.",
                        'action': f"Continuar estrat√©gia atual. Monitorar concorrentes e testar pequenas otimiza√ß√µes quando poss√≠vel (thumbnails, t√≠tulos, SEO).",
                        'impact': 'BAIXO',
                        'effort': 'Baixo'
                    })
                elif data['status'] == 'growing':
                    add_recommendation(subniche, {
                        'priority': 'low',
                        'category': 'NOSSOS CANAIS - MANTER',
                        'title': f"‚úÖ Crescimento positivo",
                        'description': f"Crescimento de {data['growth_percentage']:.1f}% nas views. Subniche em boa trajet√≥ria.",
                        'action': f"Manter estrat√©gia atual e identificar padr√µes de sucesso para replicar em outros subniches.",
                        'impact': 'BAIXO',
                        'effort': 'Baixo'
                    })

        # Ordenar recomenda√ß√µes dentro de cada subniche por prioridade
        priority_order = {'urgent': 0, 'high': 1, 'medium': 2, 'low': 3}
        for subniche in recommendations_by_subniche:
            recommendations_by_subniche[subniche]['recommendations'].sort(
                key=lambda x: priority_order.get(x['priority'], 4)
            )

        total_recommendations = sum(len(data['recommendations']) for data in recommendations_by_subniche.values())
        print(f"[ReportGenerator] {total_recommendations} recomenda√ß√µes agrupadas em {len(recommendations_by_subniche)} subniches")
        return recommendations_by_subniche

    # =========================================================================
    # SALVAR RELAT√ìRIO
    # =========================================================================

    def _save_report(self, report: Dict):
        """Salva relat√≥rio no banco de dados"""
        print("[ReportGenerator] Salvando relat√≥rio no banco...")

        try:
            self.db.table("weekly_reports").insert({
                'week_start': report['week_start'],
                'week_end': report['week_end'],
                'report_data': json.dumps(report)
            }).execute()

            print("[ReportGenerator] Relat√≥rio salvo com sucesso!")

        except Exception as e:
            print(f"[ReportGenerator] Erro ao salvar relat√≥rio: {e}")

    # =========================================================================
    # BUSCAR √öLTIMO RELAT√ìRIO
    # =========================================================================

    def get_latest_report(self) -> Dict:
        """
        Busca o relat√≥rio mais recente

        Returns:
            Dict com dados do √∫ltimo relat√≥rio
        """
        print("[ReportGenerator] Buscando √∫ltimo relat√≥rio...")

        response = self.db.table("weekly_reports")\
            .select("*")\
            .order("week_start", desc=True)\
            .limit(1)\
            .execute()

        if response.data:
            report_data = response.data[0]
            return json.loads(report_data['report_data'])

        print("[ReportGenerator] Nenhum relat√≥rio encontrado")
        return None
