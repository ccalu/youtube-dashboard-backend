"""
Scanner autom√°tico de planilhas Google Sheets

Varre todas as planilhas dos canais ativos a cada X minutos,
detecta v√≠deos prontos para upload e adiciona na fila automaticamente.

Autor: Sistema automatizado
Data: 2025-12-27
"""

import logging
from typing import List, Dict, Optional
import asyncio
from datetime import datetime
import os
import json
from google.oauth2 import service_account
import gspread
from supabase import create_client

logger = logging.getLogger(__name__)

class SpreadsheetScanner:
    """
    Scanner de planilhas Google Sheets para detec√ß√£o autom√°tica de v√≠deos.

    Caracter√≠sticas:
    - Rate limiting (processa em batches)
    - Timeout por planilha (15s)
    - Circuit breaker (desliga ap√≥s N erros)
    - Logs muito detalhados
    - Preven√ß√£o de duplicatas
    """

    def __init__(self):
        """Inicializa scanner com configura√ß√µes"""

        # Configura√ß√µes (via env vars ou padr√£o)
        self.batch_size = int(os.getenv("SCANNER_BATCH_SIZE", "2"))  # 2 para suporte 70+ canais
        self.timeout_per_sheet = int(os.getenv("SCANNER_TIMEOUT_SECONDS", "15"))
        self.max_errors = int(os.getenv("SCANNER_MAX_ERRORS", "3"))

        # Estado interno
        self.error_count = 0
        self.is_active = True

        # Conex√µes (lazy initialization)
        self._sheets_client = None
        self._supabase_client = None

        logger.info(f"üìä Scanner configurado:")
        logger.info(f"   Batch size: {self.batch_size} planilhas")
        logger.info(f"   Timeout: {self.timeout_per_sheet}s por planilha")
        logger.info(f"   Max errors: {self.max_errors}")

    @property
    def sheets_client(self):
        """Google Sheets client (singleton)"""
        if self._sheets_client is None:
            creds_json = os.getenv('GOOGLE_SHEETS_CREDENTIALS_2')
            if not creds_json:
                raise ValueError("GOOGLE_SHEETS_CREDENTIALS_2 n√£o configurado!")

            # Parse JSON credentials
            creds_dict = json.loads(creds_json)
            credentials = service_account.Credentials.from_service_account_info(
                creds_dict,
                scopes=[
                    'https://www.googleapis.com/auth/spreadsheets',
                    'https://www.googleapis.com/auth/drive'
                ]
            )

            self._sheets_client = gspread.authorize(credentials)
            logger.info("‚úÖ Google Sheets client autenticado")

        return self._sheets_client

    @property
    def supabase_client(self):
        """Supabase client (singleton)"""
        if self._supabase_client is None:
            url = os.getenv('SUPABASE_URL')
            key = os.getenv('SUPABASE_KEY')
            if not url or not key:
                raise ValueError("SUPABASE_URL ou SUPABASE_KEY n√£o configurados!")

            self._supabase_client = create_client(url, key)
            logger.info("‚úÖ Supabase client conectado")

        return self._supabase_client

    async def scan_all_spreadsheets(self):
        """
        Varre todas as planilhas dos canais ativos.

        Processo:
        1. Busca canais ativos com spreadsheet_id
        2. Processa em batches (rate limiting)
        3. Para cada planilha, detecta v√≠deos prontos
        4. Adiciona na fila se passar valida√ß√µes
        5. Logs detalhados de tudo
        """

        if not self.is_active:
            logger.warning("üö® Scanner desativado (circuit breaker)")
            return

        logger.info("=" * 80)
        logger.info("üîç SCANNER INICIADO")
        logger.info(f"‚è∞ Timestamp: {datetime.now().isoformat()}")

        start_time = datetime.now()
        total_videos_found = 0
        total_videos_added = 0
        total_videos_skipped = 0
        total_errors = 0
        total_sheets_success = 0
        total_sheets_failed = 0

        try:
            # 1. Busca canais ativos
            channels = await self._get_active_channels()

            if not channels:
                logger.warning("‚ö†Ô∏è  Nenhum canal ativo com spreadsheet_id encontrado")
                return

            logger.info(f"üìä Canais para varrer: {len(channels)}")
            logger.info("=" * 80)

            # 2. Processa em batches
            num_batches = (len(channels) - 1) // self.batch_size + 1

            for i in range(0, len(channels), self.batch_size):
                batch = channels[i:i + self.batch_size]
                batch_num = i // self.batch_size + 1

                logger.info(f"üì¶ Batch {batch_num}/{num_batches} (canais {i+1}-{i+len(batch)})")

                # Processa batch em paralelo
                tasks = [self._scan_channel(ch) for ch in batch]
                results = await asyncio.gather(*tasks, return_exceptions=True)

                # Consolida resultados
                for result in results:
                    if isinstance(result, dict):
                        total_videos_found += result['found']
                        total_videos_added += result['added']
                        total_videos_skipped += result['skipped']
                        total_sheets_success += 1  # Planilha processada com sucesso
                    elif isinstance(result, Exception):
                        logger.error(f"   ‚ùå Erro no batch: {result}")
                        total_errors += 1
                        total_sheets_failed += 1  # Planilha falhou

                # Pausa entre batches (rate limiting - Google Sheets quota: 60 req/min)
                if i + self.batch_size < len(channels):
                    await asyncio.sleep(15)  # 15s para margem de 87% (suporte 70+ canais)

            # 3. Sucesso - reseta contador de erros
            self.error_count = 0

        except Exception as e:
            logger.error(f"üíî Erro cr√≠tico no scanner: {e}", exc_info=True)
            total_errors += 1
            self.error_count += 1

            # Circuit breaker
            if self.error_count >= self.max_errors:
                self.is_active = False
                logger.critical(f"üö® SCANNER DESATIVADO ap√≥s {self.max_errors} erros consecutivos!")
                logger.critical("   Para reativar: reinicie o Railway ou defina SCANNER_ENABLED=true")
                return

        # 4. Logs finais
        elapsed = (datetime.now() - start_time).total_seconds()
        total_sheets = total_sheets_success + total_sheets_failed

        logger.info("=" * 80)
        logger.info("‚úÖ SCANNER CONCLU√çDO")
        logger.info(f"‚è±Ô∏è  Tempo total: {elapsed:.1f}s")
        logger.info(f"üìä Planilhas processadas: {total_sheets_success}/{total_sheets} ({(total_sheets_success/total_sheets*100) if total_sheets > 0 else 0:.0f}%)")
        if total_sheets_failed > 0:
            logger.warning(f"   ‚ö†Ô∏è  Falhas: {total_sheets_failed} planilhas com erro")
        logger.info(f"üìπ V√≠deos encontrados: {total_videos_found}")
        logger.info(f"‚úÖ V√≠deos adicionados: {total_videos_added}")
        logger.info(f"‚è≠Ô∏è  V√≠deos skipados: {total_videos_skipped}")
        logger.info(f"‚ùå Erros: {total_errors}")
        logger.info("=" * 80)

    async def _get_active_channels(self) -> List[Dict]:
        """Busca canais ativos com spreadsheet_id configurado"""

        try:
            result = self.supabase_client.table('yt_channels').select(
                'channel_id, channel_name, spreadsheet_id, subnicho, lingua'
            ).eq('is_active', True).not_.is_('spreadsheet_id', 'null').execute()

            return result.data or []

        except Exception as e:
            logger.error(f"‚ùå Erro ao buscar canais: {e}", exc_info=True)
            return []

    async def _scan_channel(self, channel: Dict) -> Dict:
        """
        Varre planilha de um canal espec√≠fico.

        Args:
            channel: Dict com channel_id, channel_name, spreadsheet_id

        Returns:
            Dict com found, added, skipped
        """

        channel_id = channel['channel_id']
        spreadsheet_id = channel['spreadsheet_id']
        channel_name = channel.get('channel_name', 'Unknown')

        logger.info(f"  üìä Canal: {channel_name} ({channel_id})")
        logger.info(f"     Planilha: {spreadsheet_id}")

        try:
            # Timeout de N segundos por planilha
            async with asyncio.timeout(self.timeout_per_sheet):
                result = await self._scan_spreadsheet(channel)

                # Mostra linhas lidas vs processadas (otimiza√ß√£o de √∫ltimas 15)
                if result['rows_read'] > result.get('rows_processed', 0):
                    logger.info(f"     ‚úÖ Linhas lidas: {result['rows_read']} (processadas: {result.get('rows_processed', 0)})")
                else:
                    logger.info(f"     ‚úÖ Linhas lidas: {result['rows_read']}")

                logger.info(f"     üìπ V√≠deos encontrados: {result['found']}")

                if result['added'] > 0:
                    logger.info(f"     ‚úÖ V√≠deos adicionados: {result['added']}")

                if result['skipped'] > 0:
                    logger.info(f"     ‚è≠Ô∏è  V√≠deos skipados: {result['skipped']}")

                return result

        except asyncio.TimeoutError:
            logger.warning(f"     ‚è∞ Timeout ({self.timeout_per_sheet}s) - skipando")
            return {'found': 0, 'added': 0, 'skipped': 0, 'rows_read': 0, 'rows_processed': 0}

        except Exception as e:
            logger.error(f"     ‚ùå Erro: {e}", exc_info=True)
            return {'found': 0, 'added': 0, 'skipped': 0, 'rows_read': 0, 'rows_processed': 0}

    async def _scan_spreadsheet(self, channel: Dict) -> Dict:
        """
        L√™ planilha, filtra linhas e adiciona v√≠deos prontos na fila.

        Args:
            channel: Dict com dados do canal

        Returns:
            Dict com found, added, skipped, rows_read
        """

        channel_id = channel['channel_id']
        spreadsheet_id = channel['spreadsheet_id']
        subnicho = channel.get('subnicho', '')
        lingua = channel.get('lingua', 'en')

        # 1. Abre planilha (sync - gspread n√£o √© async)
        # NOTA: Rodando em thread separada para n√£o bloquear event loop
        def _read_sheet():
            try:
                sheet = self.sheets_client.open_by_key(spreadsheet_id)
                worksheet = sheet.worksheet('P√°gina1')  # SEM espa√ßo!
                return worksheet.get_all_values()
            except gspread.WorksheetNotFound:
                logger.warning(f"     ‚ö†Ô∏è  Aba 'P√°gina1' n√£o encontrada")
                return []
            except Exception as e:
                logger.error(f"     ‚ùå Erro ao ler planilha: {e}")
                return []

        # Executa em thread pool (n√£o bloqueia)
        loop = asyncio.get_event_loop()
        all_values = await loop.run_in_executor(None, _read_sheet)

        if not all_values or len(all_values) < 2:
            return {'found': 0, 'added': 0, 'skipped': 0, 'rows_read': 0, 'rows_processed': 0}

        # 2. Otimiza√ß√£o: Processa apenas √∫ltimas 15 linhas (v√≠deos prontos s√£o sequenciais)
        total_rows = len(all_values) - 1  # -1 para excluir header
        rows_limit = 15

        # Pega √∫ltimas N linhas (ou todas se < N)
        if total_rows > rows_limit:
            rows_to_process = all_values[-rows_limit:]
            start_row_number = len(all_values) - rows_limit + 1  # +1 porque row 1 = header
        else:
            rows_to_process = all_values[1:]  # Pula header
            start_row_number = 2  # Primeira linha de dados

        found = 0
        added = 0
        skipped = 0

        for offset, row_data in enumerate(rows_to_process):
            row_idx = start_row_number + offset  # N√∫mero real da linha na planilha

            # Valida se linha est√° pronta para upload
            if self._is_video_ready(row_data):
                found += 1

                # Tenta adicionar na fila
                success = await self._add_to_queue(
                    channel_id=channel_id,
                    spreadsheet_id=spreadsheet_id,
                    row_number=row_idx,
                    row_data=row_data,
                    subnicho=subnicho,
                    lingua=lingua
                )

                if success:
                    added += 1
                else:
                    skipped += 1

        return {
            'found': found,
            'added': added,
            'skipped': skipped,
            'rows_read': total_rows,
            'rows_processed': len(rows_to_process)
        }

    def _is_video_ready(self, row_data: List[str]) -> bool:
        """
        Verifica se linha est√° pronta para upload.

        Condi√ß√µes (TODAS devem ser TRUE):
        - J (Status) == "done"
        - K (Post) == vazio
        - O (Upload) == vazio
        - A (Name) preenchido
        - M (Drive URL) preenchido

        Args:
            row_data: Lista com valores das colunas

        Returns:
            bool: True se pronto, False caso contr√°rio
        """

        # Garante que tem pelo menos 15 colunas
        if len(row_data) < 15:
            return False

        # Extrai valores (√≠ndice 0-based)
        name = row_data[0] if len(row_data) > 0 else ''           # A - Name
        status = row_data[9] if len(row_data) > 9 else ''         # J - Status
        post = row_data[10] if len(row_data) > 10 else ''         # K - Post
        video_url = row_data[12] if len(row_data) > 12 else ''    # M - Drive URL
        upload = row_data[14] if len(row_data) > 14 else ''       # O - Upload

        # Valida√ß√µes
        if status != 'done':
            return False  # N√£o renderizado

        if post and post.strip():
            return False  # J√° tem data de publica√ß√£o

        if upload and upload.strip():
            return False  # J√° tem status de upload

        if not name or not name.strip():
            return False  # Sem t√≠tulo

        if not video_url or not video_url.strip():
            return False  # Sem URL

        # ‚úÖ PASSOU EM TODAS!
        return True

    async def _add_to_queue(
        self,
        channel_id: str,
        spreadsheet_id: str,
        row_number: int,
        row_data: List[str],
        subnicho: str,
        lingua: str
    ) -> bool:
        """
        Adiciona v√≠deo na fila de upload (se n√£o existir duplicata).

        Args:
            channel_id: ID do canal
            spreadsheet_id: ID da planilha
            row_number: N√∫mero da linha
            row_data: Dados da linha
            subnicho: Subnicho do canal
            lingua: L√≠ngua do canal

        Returns:
            bool: True se adicionou, False se skipou (duplicata)
        """

        # Extrai dados
        titulo = row_data[0].strip() if len(row_data) > 0 else ''
        descricao = row_data[1].strip() if len(row_data) > 1 else ''
        video_url = row_data[12].strip() if len(row_data) > 12 else ''

        # 1. Verifica duplicata no banco
        try:
            existing = self.supabase_client.table('yt_upload_queue').select('id, status').match({
                'spreadsheet_id': spreadsheet_id,
                'sheets_row_number': row_number
            }).in_('status', ['pending', 'downloading', 'uploading']).execute()

            if existing.data:
                logger.info(f"        ‚è≠Ô∏è  Row {row_number}: J√° em processamento (ID {existing.data[0]['id']})")
                return False

        except Exception as e:
            logger.error(f"        ‚ùå Erro ao verificar duplicata: {e}")
            return False

        # 2. Adiciona na fila
        try:
            result = self.supabase_client.table('yt_upload_queue').insert({
                'channel_id': channel_id,
                'video_url': video_url,
                'titulo': titulo,
                'descricao': descricao,
                'subnicho': subnicho,
                'lingua': lingua,
                'spreadsheet_id': spreadsheet_id,
                'sheets_row_number': row_number,
                'status': 'pending'
            }).execute()

            if not result.data:
                logger.error(f"        ‚ùå Erro ao inserir na fila (row {row_number})")
                return False

            upload_id = result.data[0]['id']
            logger.info(f"        ‚úÖ Row {row_number}: \"{titulo[:40]}...\" ‚Üí Fila (ID {upload_id})")

            # 3. Marca planilha como "processing" (DESABILITADO - economiza 1 req/v√≠deo)
            # await self._update_sheet_status(spreadsheet_id, row_number, "‚è≥ processing...")

            return True

        except Exception as e:
            logger.error(f"        ‚ùå Erro ao adicionar na fila (row {row_number}): {e}", exc_info=True)
            return False

    async def _update_sheet_status(self, spreadsheet_id: str, row_number: int, status: str):
        """Atualiza coluna O (Upload) na planilha"""

        try:
            def _update():
                sheet = self.sheets_client.open_by_key(spreadsheet_id)
                worksheet = sheet.worksheet('P√°gina1')
                worksheet.update_cell(row_number, 15, status)  # Coluna O = 15

            # Executa em thread pool
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(None, _update)

        except Exception as e:
            logger.warning(f"        ‚ö†Ô∏è  Erro ao atualizar planilha (row {row_number}): {e}")
