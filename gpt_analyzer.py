"""
GPT Comment Analyzer - An√°lise inteligente de coment√°rios com OpenAI
Processa coment√°rios do YouTube usando GPT-4 para extrair insights detalhados
Author: Cellibs
Date: 2026-01-19
"""

import os
import json
import logging
import asyncio
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from openai import OpenAI
from dotenv import load_dotenv
import time

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Carregar vari√°veis de ambiente
load_dotenv()


class GPTAnalyzer:
    """Analisador de coment√°rios usando OpenAI GPT"""

    def __init__(self):
        """Inicializa cliente OpenAI e configura√ß√µes"""
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            logger.error("‚ùå OPENAI_API_KEY n√£o configurada no .env")
            raise ValueError("OPENAI_API_KEY n√£o configurada no .env")

        logger.info(f"‚úÖ OpenAI API Key carregada: {api_key[:10]}...{api_key[-4:]}")

        self.client = OpenAI(api_key=api_key)
        self.model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")  # Modelo padr√£o
        self.max_tokens_per_request = 16000  # Limite seguro para gpt-4o-mini

        logger.info(f"‚úÖ GPTAnalyzer inicializado - Modelo: {self.model}")

        # M√©tricas di√°rias
        self.daily_metrics = {
            'total_analyzed': 0,
            'total_tokens_input': 0,
            'total_tokens_output': 0,
            'total_requests': 0,
            'total_errors': 0,
            'total_time_ms': 0,
            'estimated_cost_usd': 0.0,
            'high_confidence_count': 0,
            'medium_confidence_count': 0,
            'low_confidence_count': 0
        }

        logger.info(f"GPTAnalyzer inicializado com modelo: {self.model}")

    def _get_system_prompt(self, canal_name: str = "", subnicho: str = "") -> str:
        """
        Retorna o system prompt otimizado para an√°lise de coment√°rios.
        """
        return f"""Voc√™ √© um analista especializado em coment√°rios de canais YouTube brasileiros.

CONTEXTO DO CANAL:
- Nome: {canal_name}
- Nicho: {subnicho if subnicho else "Dark YouTube / Terror / Mist√©rio"}
- Idioma principal: Portugu√™s Brasileiro
- P√∫blico: Brasileiro, jovem-adulto

SUA TAREFA:
Analisar coment√°rios com precis√£o profissional, retornando um JSON estruturado.

DIRETRIZES IMPORTANTES:
1. Identifique o sentimento REAL (considere sarcasmo, ironia, contexto brasileiro)
2. Detecte problemas ESPEC√çFICOS (n√£o gen√©ricos)
3. Priorize coment√°rios que requerem a√ß√£o imediata
4. Considere g√≠rias e express√µes brasileiras
5. Sugira respostas aut√™nticas e personalizadas (n√£o robotizadas)
6. Identifique oportunidades de conte√∫do nas perguntas/sugest√µes

PRIORIZA√á√ÉO (0-100):
- 90-100: Problemas cr√≠ticos que impedem visualiza√ß√£o
- 70-89: Erros factuais, problemas t√©cnicos s√©rios
- 50-69: Sugest√µes valiosas, perguntas relevantes
- 30-49: Elogios significativos, feedback construtivo
- 10-29: Coment√°rios neutros informativos
- 0-9: Spam, irrelevante, apenas emoji

CATEGORIAS POSS√çVEIS:
- problem: Relata problema t√©cnico ou de conte√∫do
- praise: Elogio ao canal ou v√≠deo
- question: Pergunta genu√≠na
- suggestion: Sugest√£o de melhoria ou conte√∫do
- feedback: Feedback geral (pode ser misto)"""

    def _create_analysis_prompt(self, comments: List[Dict]) -> str:
        """
        Cria o prompt para an√°lise em batch de coment√°rios.
        """
        comments_text = []
        for i, comment in enumerate(comments, 1):
            text = comment.get('text', comment.get('comment_text_original', ''))
            author = comment.get('author_name', 'An√¥nimo')
            likes = comment.get('like_count', 0)

            comments_text.append(f"""
Coment√°rio #{i}:
Autor: {author}
Likes: {likes}
Texto: {text}
""")

        return f"""Analise os seguintes {len(comments)} coment√°rios e retorne um JSON com a an√°lise de CADA um.

COMENT√ÅRIOS:
{''.join(comments_text)}

IMPORTANTE:
- Retorne APENAS um JSON v√°lido, sem explica√ß√µes adicionais
- O JSON deve ter a chave "comments" com um array de objetos
- Cada objeto deve ter EXATAMENTE a estrutura especificada abaixo
- Se n√£o conseguir determinar algo, use null

ESTRUTURA ESPERADA:
{{
  "comments": [
    {{
      "index": 1,
      "translation_pt": "TRADU√á√ÉO ADAPTADA para portugu√™s brasileiro (n√£o literal, mas contextualizada e natural)",
      "is_translated": true|false (true se o coment√°rio foi traduzido, false se j√° estava em PT),
      "sentiment": {{
        "category": "positive|negative|neutral|mixed",
        "score": -1.0 a 1.0,
        "confidence": 0.0 a 1.0,
        "nuances": ["sarcasm", "irony", "genuine", "emotional", etc]
      }},
      "categories": ["problem", "praise", "question", "suggestion", "feedback"],
      "primary_category": "categoria principal",
      "subcategories": {{
        "problem": ["audio", "video", "content", "technical"],
        "praise": ["content", "editing", "narration", "thumbnail"]
      }},
      "topics": ["t√≥pico1", "t√≥pico2"],
      "key_points": ["ponto principal 1", "ponto 2"],
      "emotional_tone": "angry|happy|frustrated|excited|neutral|concerned|curious|grateful",
      "intent": "criticize|compliment|ask|suggest|inform|express|engage",
      "context_indicators": ["frequent_viewer", "first_time", "fan", "critic"],
      "language": "pt|en|es|other",
      "priority_score": 0-100,
      "urgency_level": "low|medium|high|critical",
      "requires_response": true|false,
      "suggested_response": "Texto da resposta sugerida ou null",
      "response_tone": "formal|friendly|empathetic|professional|grateful",
      "insight_summary": "Resumo do insight principal",
      "actionable_items": ["a√ß√£o 1", "a√ß√£o 2"] ou null
    }}
  ]
}}

IMPORTANTE SOBRE TRADU√á√ÉO:
- Se o coment√°rio N√ÉO est√° em portugu√™s: traduza para PT-BR natural e contextualizado
- Se o coment√°rio J√Å est√° em portugu√™s: apenas copie o texto original e marque is_translated como false
- Detecte portugu√™s por palavras como: que, para, com, n√£o, voc√™, muito, √©, est√°, fazer, ter
- Use linguagem natural, n√£o tradu√ß√£o literal
- Adapte g√≠rias e express√µes para equivalentes em PT-BR
- Mantenha o tom e emo√ß√£o originais"""

    async def analyze_batch(
        self,
        comments: List[Dict],
        video_title: str = "",
        canal_name: str = "",
        batch_size: int = 15  # Reduzido para evitar erros de JSON
    ) -> List[Dict]:
        """
        Analisa um lote de coment√°rios usando GPT.

        Args:
            comments: Lista de coment√°rios para analisar
            video_title: T√≠tulo do v√≠deo (contexto)
            canal_name: Nome do canal
            batch_size: Tamanho m√°ximo do batch (padr√£o 15)

        Returns:
            Lista de coment√°rios com an√°lise GPT completa
        """
        if not comments:
            logger.warning("‚ö†Ô∏è Lista de coment√°rios vazia, retornando []")
            return []

        logger.info(f"üìä Iniciando an√°lise GPT de {len(comments)} coment√°rios - Canal: {canal_name}")
        analyzed_comments = []

        # Processar em batches para economizar tokens
        total_batches = (len(comments) + batch_size - 1) // batch_size
        for i in range(0, len(comments), batch_size):
            batch = comments[i:i + batch_size]
            batch_num = (i // batch_size) + 1
            logger.info(f"üîÑ Processando batch {batch_num}/{total_batches} com {len(batch)} coment√°rios...")

            try:
                # Fazer a an√°lise do batch
                batch_analysis = await self._analyze_single_batch(batch, video_title, canal_name)
                logger.info(f"‚úÖ Batch {batch_num} analisado: {len(batch_analysis)} respostas retornadas")

                # Combinar coment√°rios originais com an√°lise
                for j, comment in enumerate(batch):
                    if j < len(batch_analysis):
                        analysis = batch_analysis[j]

                        # Merge dados originais com an√°lise
                        analyzed_comment = {
                            'comment_id': comment.get('comment_id', comment.get('commentId')),
                            'video_id': comment.get('video_id', comment.get('videoId')),
                            'video_title': video_title or comment.get('video_title'),
                            'author_name': comment.get('author_name', comment.get('author')),
                            'author_channel_id': comment.get('author_channel_id'),
                            'comment_text_original': comment.get('text', comment.get('comment_text_original')),
                            'comment_text_pt': analysis.get('translation_pt', ''),  # TRADU√á√ÉO DO GPT
                            'is_translated': analysis.get('is_translated', False),  # FLAG DE TRADU√á√ÉO
                            'like_count': comment.get('like_count', comment.get('likeCount', 0)),
                            'reply_count': comment.get('reply_count', comment.get('replyCount', 0)),
                            'is_reply': comment.get('is_reply', False),
                            'parent_comment_id': comment.get('parent_comment_id'),
                            'published_at': comment.get('published_at', comment.get('publishedAt')),

                            # Adicionar an√°lise GPT
                            'gpt_analysis': {
                                'sentiment': analysis.get('sentiment', {}),
                                'categories': analysis.get('categories', []),
                                'primary_category': analysis.get('primary_category'),
                                'subcategories': analysis.get('subcategories', {}),
                                'topics': analysis.get('topics', []),
                                'key_points': analysis.get('key_points', []),
                                'emotional_tone': analysis.get('emotional_tone'),
                                'intent': analysis.get('intent'),
                                'context_indicators': analysis.get('context_indicators', []),
                                'language': analysis.get('language', 'pt')
                            },

                            # Campos extra√≠dos para queries r√°pidas
                            'sentiment_category': analysis.get('sentiment', {}).get('category'),
                            'sentiment_score': analysis.get('sentiment', {}).get('score'),
                            'sentiment_confidence': analysis.get('sentiment', {}).get('confidence'),
                            'categories': analysis.get('categories', []),
                            'primary_category': analysis.get('primary_category'),
                            'emotional_tone': analysis.get('emotional_tone'),
                            'priority_score': analysis.get('priority_score', 0),
                            'urgency_level': analysis.get('urgency_level', 'low'),
                            'requires_response': analysis.get('requires_response', False),
                            'suggested_response': analysis.get('suggested_response'),
                            'response_tone': analysis.get('response_tone'),
                            'insight_summary': analysis.get('insight_summary'),
                            'actionable_items': analysis.get('actionable_items')
                        }

                        analyzed_comments.append(analyzed_comment)

                        # Atualizar m√©tricas de confian√ßa
                        confidence = analysis.get('sentiment', {}).get('confidence', 0)
                        if confidence >= 0.8:
                            self.daily_metrics['high_confidence_count'] += 1
                        elif confidence >= 0.5:
                            self.daily_metrics['medium_confidence_count'] += 1
                        else:
                            self.daily_metrics['low_confidence_count'] += 1
                    else:
                        # Se an√°lise falhou para este coment√°rio, adicionar sem an√°lise
                        logger.warning(f"An√°lise n√£o retornada para coment√°rio {j+1}")
                        analyzed_comments.append(comment)

            except Exception as e:
                logger.error(f"‚ùå ERRO ao analisar batch {batch_num}: {str(e)}")
                logger.error(f"   Canal: {canal_name}, V√≠deo: {video_title}")
                logger.error(f"   Batch size: {len(batch)}")
                self.daily_metrics['total_errors'] += 1
                # N√ÉO adicionar coment√°rios sem an√°lise - melhor falhar do que salvar incompleto
                logger.warning(f"‚ö†Ô∏è Batch {batch_num} N√ÉO ser√° salvo devido ao erro")

            # Pequena pausa entre batches para evitar rate limit
            if i + batch_size < len(comments):
                await asyncio.sleep(0.5)

        logger.info(f"‚úÖ Total de {len(analyzed_comments)} coment√°rios analisados")
        self.daily_metrics['total_analyzed'] += len(analyzed_comments)

        return analyzed_comments

    async def _analyze_single_batch(
        self,
        batch: List[Dict],
        video_title: str,
        canal_name: str
    ) -> List[Dict]:
        """
        Analisa um √∫nico batch de coment√°rios.

        Returns:
            Lista com an√°lises dos coment√°rios
        """
        start_time = time.time()

        try:
            logger.info(f"üöÄ Iniciando an√°lise do batch - {len(batch)} coment√°rios")

            # Preparar mensagens
            messages = [
                {"role": "system", "content": self._get_system_prompt(canal_name)},
                {"role": "user", "content": self._create_analysis_prompt(batch)}
            ]

            logger.info(f"üìù Prompt preparado - Tamanho aproximado: {len(str(messages))} caracteres")

            # Chamar API da OpenAI
            logger.info(f"üåê Chamando OpenAI API - Modelo: {self.model}")
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.3,  # Mais determin√≠stico para an√°lises
                max_tokens=4000,  # Suficiente para ~30 coment√°rios
                response_format={"type": "json_object"}  # For√ßa resposta em JSON
            )
            logger.info("‚úÖ Resposta recebida da OpenAI")

            # Processar resposta
            content = response.choices[0].message.content

            # Parse JSON
            try:
                logger.info(f"üìã Tamanho da resposta: {len(content)} caracteres")
                result = json.loads(content)
                comments_analysis = result.get('comments', [])
                logger.info(f"‚úÖ JSON parseado com sucesso - {len(comments_analysis)} an√°lises retornadas")

                # Validar que temos an√°lises v√°lidas
                if not comments_analysis or len(comments_analysis) == 0:
                    logger.error(f"‚ùå GPT retornou JSON v√°lido mas SEM an√°lises")
                    logger.error(f"   Esperado: {len(batch)} an√°lises")
                    logger.error(f"   Recebido: 0 an√°lises")
                    logger.error(f"   Resposta completa: {content[:500]}...")
                    raise ValueError("Nenhuma an√°lise retornada pelo GPT")

            except json.JSONDecodeError as e:
                logger.error(f"‚ùå ERRO ao fazer parse do JSON: {e}")
                logger.error(f"   Resposta GPT (primeiros 500 chars): {content[:500]}")
                logger.error(f"   Resposta GPT (√∫ltimos 500 chars): {content[-500:]}")
                raise  # Re-lan√ßar exce√ß√£o para ser capturada no n√≠vel superior

            # Atualizar m√©tricas
            self.daily_metrics['total_requests'] += 1
            if response.usage:
                self.daily_metrics['total_tokens_input'] += response.usage.prompt_tokens
                self.daily_metrics['total_tokens_output'] += response.usage.completion_tokens

                # Calcular custo estimado (GPT-4o-mini)
                input_cost = (response.usage.prompt_tokens / 1_000_000) * 0.15  # $0.15 per 1M
                output_cost = (response.usage.completion_tokens / 1_000_000) * 0.60  # $0.60 per 1M
                self.daily_metrics['estimated_cost_usd'] += (input_cost + output_cost)

            # Tempo de resposta
            elapsed_ms = int((time.time() - start_time) * 1000)
            self.daily_metrics['total_time_ms'] += elapsed_ms

            logger.info(f"‚úÖ Batch analisado em {elapsed_ms}ms - {len(comments_analysis)} coment√°rios")

            return comments_analysis

        except Exception as e:
            logger.error(f"‚ùå ERRO CR√çTICO na chamada GPT: {str(e)}")
            logger.error(f"   Tipo do erro: {type(e).__name__}")
            logger.error(f"   Canal: {canal_name}")
            logger.error(f"   Batch size: {len(batch)}")

            # Registrar erro nas m√©tricas
            self.daily_metrics['total_errors'] += 1

            # Re-lan√ßar exce√ß√£o para ser tratada no n√≠vel superior
            # N√ÉO retornar [] pois isso faz parecer que funcionou
            raise

    async def analyze_single_comment(self, comment: Dict, context: Dict = None) -> Dict:
        """
        Analisa um √∫nico coment√°rio (√∫til para testes ou an√°lise em tempo real).

        Args:
            comment: Coment√°rio para analisar
            context: Contexto adicional (canal, v√≠deo, etc)

        Returns:
            Coment√°rio com an√°lise completa
        """
        batch_result = await self.analyze_batch(
            [comment],
            video_title=context.get('video_title', '') if context else '',
            canal_name=context.get('canal_name', '') if context else '',
            batch_size=1
        )

        return batch_result[0] if batch_result else comment

    def get_daily_metrics(self) -> Dict:
        """
        Retorna m√©tricas di√°rias de uso.

        Returns:
            Dicion√°rio com m√©tricas do dia
        """
        # Calcular m√©dias
        avg_response_time = 0
        success_rate = 0

        if self.daily_metrics['total_requests'] > 0:
            avg_response_time = self.daily_metrics['total_time_ms'] // self.daily_metrics['total_requests']
            success_count = self.daily_metrics['total_requests'] - self.daily_metrics['total_errors']
            success_rate = (success_count / self.daily_metrics['total_requests']) * 100

        return {
            'total_analyzed': self.daily_metrics['total_analyzed'],
            'total_tokens_input': self.daily_metrics['total_tokens_input'],
            'total_tokens_output': self.daily_metrics['total_tokens_output'],
            'avg_response_time_ms': avg_response_time,
            'success_rate': round(success_rate, 2),
            'errors_count': self.daily_metrics['total_errors'],
            'estimated_cost_usd': round(self.daily_metrics['estimated_cost_usd'], 2),
            'high_confidence_count': self.daily_metrics['high_confidence_count'],
            'medium_confidence_count': self.daily_metrics['medium_confidence_count'],
            'low_confidence_count': self.daily_metrics['low_confidence_count']
        }

    def reset_daily_metrics(self):
        """Reseta as m√©tricas di√°rias (chamar √† meia-noite)."""
        self.daily_metrics = {
            'total_analyzed': 0,
            'total_tokens_input': 0,
            'total_tokens_output': 0,
            'total_requests': 0,
            'total_errors': 0,
            'total_time_ms': 0,
            'estimated_cost_usd': 0.0,
            'high_confidence_count': 0,
            'medium_confidence_count': 0,
            'low_confidence_count': 0
        }
        logger.info("M√©tricas di√°rias resetadas")


# Fun√ß√£o auxiliar para teste r√°pido
async def test_analyzer():
    """Fun√ß√£o de teste do analisador"""
    analyzer = GPTAnalyzer()

    # Coment√°rios de exemplo
    test_comments = [
        {
            'comment_id': 'test1',
            'text': 'Cara, o √°udio t√° muito baixo nesse v√≠deo! Tive que colocar no m√°ximo e ainda assim mal consegui ouvir.',
            'author_name': 'Jo√£o Silva',
            'like_count': 45
        },
        {
            'comment_id': 'test2',
            'text': 'Melhor canal de terror do YouTube brasileiro! Continua com esse trabalho incr√≠vel!',
            'author_name': 'Maria Santos',
            'like_count': 23
        },
        {
            'comment_id': 'test3',
            'text': 'Quando vai sair a parte 2? Fiquei muito curioso!',
            'author_name': 'Pedro Costa',
            'like_count': 12
        }
    ]

    # Analisar
    results = await analyzer.analyze_batch(
        test_comments,
        video_title="A Casa Assombrada - Parte 1",
        canal_name="Canal Dark",
        batch_size=10
    )

    # Mostrar resultados
    for result in results:
        print("\n" + "="*50)
        print(f"Autor: {result['author_name']}")
        print(f"Texto: {result['comment_text_original']}")
        print(f"Sentimento: {result.get('sentiment_category')} (score: {result.get('sentiment_score')})")
        print(f"Categorias: {result.get('categories')}")
        print(f"Prioridade: {result.get('priority_score')}")
        print(f"Requer resposta: {result.get('requires_response')}")
        if result.get('suggested_response'):
            print(f"Resposta sugerida: {result['suggested_response']}")

    # Mostrar m√©tricas
    print("\n" + "="*50)
    print("M√âTRICAS DO DIA:")
    metrics = analyzer.get_daily_metrics()
    for key, value in metrics.items():
        print(f"  {key}: {value}")


if __name__ == "__main__":
    # Teste local
    asyncio.run(test_analyzer())